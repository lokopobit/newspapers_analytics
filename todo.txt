### STEP 1: CRAWLING AND STORING ### 
already_cleaned and already_stored jsons must be improved with a path length (for example) so that 
crawles of the same day are not duplicated in the mongodb
Another option to last paragraph problem is to store articles urls and avoid recrawling and remove duplicated recrawls.
newsplease package datetime parser fails sometimes
To increase webpages index urls extraction with selenium launch driver oonce and 
create new tabs instead of launching-closing driver for each url.
main() function of get_news.py script can be optimized by merging cleaning() and insert2mong() functions at os.listdir/scandir level
Included code lines in parse_crawler.py to avoid re-downloading are not properly placed. They are now placed in the spider
url extraction of html but must be placed rigth before saving the json and html of that article.
elasticsearch database
https://www.prensaescrita.com/europa/turquia.php
Change variable names and file names (storing_and_cleaning)


### STEP 2: ANALYTICS ###
similarity measures between titulares texto (como para comprobar plagios)
search for huelva.es alcaldes in newspapers
cuantas veces aparecen las personas, las cosas en general.
analisis de sentimiento de las imagenes (politicos...)
comparacion entre las imagenes de una misma noticia.
clasificador de noticias
anuncios de ese periodico, asi como empresas relacionadas
periodicos relacionados entre si, bajo la misma direccion o empresa mediatica.
comprobar si los jefes del periodico poseen otras empresas.
news tracking -> news cronologhy
analisis de noticias estacional: en verano, navidad, semana santa, ...
5W1H
GDELT Project 
Related news to a selected one in one province, newspaper, country...
https://stackoverflow.com/questions/57189358/free-api-similar-to-google-translate-for-python
https://canarduck.gitlab.io/systranio/


### STEP 3: ###
Twitter api









C:\Users\juan\AppData\Local\Continuum\anaconda3\Lib\site-packages\newsplease\helper_classes\
commit-push newsplease library modified scripts: parse_crawler

